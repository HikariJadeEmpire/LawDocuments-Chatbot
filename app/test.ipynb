{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\rastu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.0.2)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\rastu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.23.25)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in c:\\users\\rastu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pymupdf) (1.23.22)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pythainlp -U\n",
    "# !pip install -U sentence-transformers\n",
    "\n",
    "!pip install pypdf pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythaiNLP : 5.0.1\n",
      "Sentence Transformers : 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pythainlp, sentence_transformers\n",
    "\n",
    "print(f\"PythaiNLP : {pythainlp.__version__}\")\n",
    "print(f\"Sentence Transformers : {sentence_transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: thai2fit_wv\n",
      "- Downloading: thai2fit_wv 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d744fabbb1b34ddda3f3eb7f201f3ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62452646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'เรือ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.word_vector import WordVector\n",
    "\n",
    "wv = WordVector(model_name=\"thai2fit_wv\")\n",
    "words = ['ดีไซน์เนอร์', 'พนักงานเงินเดือน', 'หมอ', 'เรือ']\n",
    "wv.doesnt_match(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbf1cc7e1cf42b0a381df0d78637858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38d7b5810d5448dae845310e95fae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c374069f908a4ce1856d19cb4c19e8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da27bd7f585e42d68b4790598fcee8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbb04c3c083438381597a53b9f46397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcbcf6d897d42c49958c68873bb88b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50de5c1fcf314addb0b224ee4d27a6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff254911144e82ae543a321cae5f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af7dd206b93405a9ba1202c14ac399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631dc0cb752e4109838268cadf7ac6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb5e0f7f9ee420a8beeb13b42070660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14317979 -0.23076151 -0.0139477  ...  0.03993538  0.10085307\n",
      "  -0.19941318]\n",
      " [ 0.0399936  -0.20410606 -0.01313243 ...  0.02634661 -0.20096205\n",
      "  -0.1451545 ]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03763687 -0.28697896 -0.01310425 ...  0.08947691 -0.01551844\n",
      "  -0.06878129]\n",
      " [ 0.09034583  0.16859867 -0.02084779 ...  0.07426576  0.01026654\n",
      "  -0.04596039]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"ทดสอบภาษาไทย\", \"ดีจริงหรือแค่หลอก แค่มาหยอกไปวันๆ\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b800cab2fca44a559fe804efefa411a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3052752a9cce416d8ac1522e3fc8d413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/713 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcd4742061e46caad8a7b9a55f07770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a7ef11dabb4ca0969f3b62c933376c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75aad879a3464ebeb02e4326f1431da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/13.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8304899c69174701a330cb8c45ecaea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/305 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bb5494642a4fc0b54aa7d3196601d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7059439   0.64715075 -1.3627945  ... -0.6020316  -0.6800522\n",
      "   0.05652151]\n",
      " [ 1.6544622   0.21197516 -0.71227956 ...  0.57853884 -1.4006945\n",
      "   0.46957   ]]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"kornwtp/simcse-model-phayathaibert\")\n",
    "sentences = [\"ทดสอบภาษาไทย\", \"ดีจริงหรือแค่หลอก แค่มาหยอกไปวันๆ\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    raise TypeError\n",
    "except :\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LawApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"type\":\"user\",\"id\":\"655f3cb7337a5d2e37bc004b\",\"name\":\"Punnathorn\",\"fullname\":\"Mingkwan\",\"email\":\"rastuniing@hotmail.com\",\"emailVerified\":true,\"canPay\":false,\"isPro\":false,\"periodEnd\":null,\"avatarUrl\":\"/avatars/7913eccc7c8ac63773a0a9d2c14bc901.svg\",\"orgs\":[],\"auth\":{\"type\":\"access_token\",\"accessToken\":{\"displayName\":\"using-model\",\"role\":\"read\"}}}'\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "## API\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "huggingface_api = os.getenv('huggingface_api')\n",
    "cohere_api = os.getenv('cohere_api')\n",
    "openai_api = os.getenv('openai_api')\n",
    "# huggingface_api = None\n",
    "\n",
    "url = 'https://huggingface.co/api/whoami-v2'\n",
    "headers = {'Authorization': \"Bearer {token}\".format(token=huggingface_api)}\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "print(r.content)\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kornwtp/simcse-model-phayathaibert'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import embeddings\n",
    "\n",
    "m = embeddings.embeddings_model()\n",
    "m.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7059439 ,  0.64715075, -1.3627945 , ..., -0.6020316 ,\n",
       "        -0.6800522 ,  0.05652151],\n",
       "       [ 1.6544622 ,  0.21197516, -0.71227956, ...,  0.57853884,\n",
       "        -1.4006945 ,  0.46957   ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"ทดสอบภาษาไทย\", \"ดีจริงหรือแค่หลอก แค่มาหยอกไปวันๆ\"]\n",
    "tm = m.to_vec(test)\n",
    "\n",
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors : 2\n",
      "shape of vectors : (2, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of vectors : {len(tm)}\")\n",
    "print(f\"shape of vectors : {tm.shape}\")\n",
    "\n",
    "type(tm.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".txt\n",
      ".docx\n"
     ]
    }
   ],
   "source": [
    "ll = os.listdir(\"../docs_storage\")\n",
    "for i in ll :\n",
    "    tes = \".\"+i.split(\".\")[1]\n",
    "\n",
    "    print(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upload.py', '__pycache__', 'main.py', 'test.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(Path(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"main.py\").parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digital-money-srettha\n",
      "News\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../db/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = Path(\"main.py\").parent\n",
    "db_path = Path(main_path,\"..\")\n",
    "\n",
    "docs_path = Path(main_path,\"..\",\"docs_storage\")\n",
    "\n",
    "for i in os.listdir(docs_path):\n",
    "    print(i.split(\".\")[0])\n",
    "    \n",
    "os.path.join(db_path,\"db/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['digital-money-srettha.txt', 'News.docx']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(docs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import upload\n",
    "upload_docs = upload.LangChainDocLoaders(pdf_loader=\"pymupdf\")\n",
    "\n",
    "check1 = upload_docs.load_document(\"../docs_storage/Por_Ror_Bor_2542.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ส ำนัก งา น คณะ ก รร ม การก ฤ ษฎีกา ส ำนัก งาน คณะ ก รร ม การก ฤ ษฎีกา\\nส ำนัก งา น คณะ ก รร ม การก ฤ ษฎีกา ส ำนัก งาน คณะ ก รร ม การก ฤ ษฎีกา ส ำนัก งาน คณะกร รม การก ฤ ษฎีกา\\nพระราชบัญญัติ\\nการศึกษาแห่งชาติ\\nพ.ศ. ๒๕๔๒\\nภูมิพลอดุลยเดช ป.ร.\\nให้ไว้ณ วันที่ ๑๔ สิงหาคม พ.ศ. ๒๕๔๒\\nเป็นปีที่ ๕๔ ในรัชกาลปัจจุบัน\\nพระบาทสมเด็จพระปรมินทรมหาภูมิพลอดุลยเดช มีพระบรมราชโองการโปรดเกล้าฯ\\nให้ประกาศว่า\\nโดยที่เป็นการสมควรให้มีกฎหมายว่าด้วยการศึกษาแห่งชาติ\\nพระราชบัญญัตินี้มีบทบัญญัติบางประการเกี่ยวกับการจำกัดสิทธิและเสรีภาพของ\\nบุคคล ซึ่งมาตรา ๒๙ ประกอบกับมาตรา ๕๐ ของรัฐธรรมนูญแห่งราชอาณาจักรไทย บัญญัติให้กระทำได้\\nโดยอาศัยอำนาจตามบทบัญญัติแห่งกฎหมาย'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1[\"child_documents\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path = Path(Path(\"main.py\").parent,\"..\")\n",
    "\n",
    "d = os.listdir(db_path)\n",
    "os.path.exists(db_path/\"vectors_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import m_vector_db\n",
    "\n",
    "tn = \"Table-0\"\n",
    "db = m_vector_db.vectordb_start(huggingface_api_key=huggingface_api,\n",
    "                                embed_model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "# db.add(table_name=tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.add(table_name=tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.retrieve(query=\"เศรษฐาคือใคร ทำอะไร\", table_name=tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST RESULT : []\n",
      "DISTANCE : []\n"
     ]
    }
   ],
   "source": [
    "best_doc = (results['documents'][0])[:5]\n",
    "distance = (results['distances'][0])[0:5]\n",
    "\n",
    "print(F\"BEST RESULT : {best_doc}\\nDISTANCE : {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: '..\\\\vectors_db\\\\chroma.sqlite3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13748\\204691142.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Table-0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\DATA_Science\\GitHub\\LawDocuments-Chatbot\\app\\m_vector_db.py\u001b[0m in \u001b[0;36mremove_db\u001b[1;34m(self, table_name)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_path\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m\"vectors_db\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_path\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m\"vectors_db\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# for i in db_check:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: '..\\\\vectors_db\\\\chroma.sqlite3'"
     ]
    }
   ],
   "source": [
    "db.remove_db(table_name=tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n"
     ]
    }
   ],
   "source": [
    "thislist = [\"apple\", \"banana\", \"cherry\"]\n",
    "thislist.pop(0)\n",
    "\n",
    "print(thislist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/hikarii/anaconda3/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
      "Requirement already satisfied: certifi in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: openai in /Users/hikarii/anaconda3/lib/python3.10/site-packages (1.1.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/hikarii/anaconda3/lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.1.1\n",
      "    Uninstalling openai-1.1.1:\n",
      "      Successfully uninstalled openai-1.1.1\n",
      "Successfully installed openai-1.12.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install cohere\n",
    "!pip install openai\n",
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: cohere\n",
      "Version: 4.36\n",
      "Summary: \n",
      "Home-page: \n",
      "Author: Cohere\n",
      "Author-email: \n",
      "License: \n",
      "Location: /Users/hikarii/anaconda3/lib/python3.10/site-packages\n",
      "Requires: aiohttp, backoff, fastavro, importlib_metadata, requests, urllib3\n",
      "Required-by: \n",
      "Name: openai\n",
      "Version: 1.12.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: /Users/hikarii/anaconda3/lib/python3.10/site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show cohere\n",
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.Client(cohere_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can understand many languages to varying degrees of fluency; as an AI language model, my performance depends on the amount of data I have available to train on, as well as how widely spoken and studied a given language is. Here is a list of some of the top languages I can assist with: \n",
      "\n",
      "1. English (United States)\n",
      "2. Mandarin (Chinese)\n",
      "3. Spanish (Spain)\n",
      "4. Hindi (India)\n",
      "5. French (France)\n",
      "6. Arabic (Saudi Arabia)\n",
      "7. Portuguese (Brazil)\n",
      "8. Japanese (Japan)\n",
      "9. Russian (Russia)\n",
      "10. Italian (Italy)\n",
      "\n",
      "However, as an AI language model, I can understand many more languages to different degrees, and I aim to continuously learn and improve my understanding through new data and updates.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "message = \"list the top 20 languages you can understand\"\n",
    "\t\n",
    "# generate a response with the current chat history\n",
    "response = co.chat(\n",
    "    message,\n",
    "    temperature=0.8,\n",
    "    chat_history=chat_history\n",
    ")\n",
    "answer = response.text\n",
    "    \n",
    "print(answer)\n",
    "\n",
    "# add message and answer to the chat history\n",
    "user_message = {\"user_name\": \"User\", \"text\": message}\n",
    "bot_message = {\"user_name\": \"Chatbot\", \"text\": answer}\n",
    "\n",
    "chat_history.append(user_message)\n",
    "chat_history.append(bot_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My training data is comprised of many different languages, including Thai. I cannot provide specific details about the proportion or amount of language data I have been trained on, but can assure you that it encompasses a diverse range of languages from different populations and regions. \n",
      "\n",
      "You can ask me specific questions in Thai, and I'll do my best to respond accurately and help you with the content you need.\n"
     ]
    }
   ],
   "source": [
    "message = \"what is the proportion of Thai language that you trained\"\n",
    "\t\n",
    "# generate a response with the current chat history\n",
    "response = co.chat(\n",
    "    message,\n",
    "    temperature=0.8,\n",
    "    chat_history=chat_history\n",
    ")\n",
    "answer = response.text\n",
    "    \n",
    "print(answer)\n",
    "\n",
    "# add message and answer to the chat history\n",
    "user_message = {\"user_name\": \"User\", \"text\": message}\n",
    "bot_message = {\"user_name\": \"Chatbot\", \"text\": answer}\n",
    "\n",
    "chat_history.append(user_message)\n",
    "chat_history.append(bot_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am unable to understand this query sentences as it is written in Thai. Please restate your question in English, or opt for a virtual keyboard if you would like to type in Thai.\n"
     ]
    }
   ],
   "source": [
    "message = \"ผีตาโขนอยู่จังหวัดอะไร\"\n",
    "\t\n",
    "# generate a response with the current chat history\n",
    "response = co.chat(\n",
    "    message,\n",
    "    temperature=0.8,\n",
    "    chat_history=chat_history\n",
    ")\n",
    "answer = response.text\n",
    "    \n",
    "print(answer)\n",
    "\n",
    "# add message and answer to the chat history\n",
    "user_message = {\"user_name\": \"User\", \"text\": message}\n",
    "bot_message = {\"user_name\": \"Chatbot\", \"text\": answer}\n",
    "\n",
    "chat_history.append(user_message)\n",
    "chat_history.append(bot_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_name': 'User', 'text': 'list the top 20 languages you can understand'},\n",
       " {'user_name': 'Chatbot',\n",
       "  'text': 'I can understand many languages to varying degrees of fluency; as an AI language model, my performance depends on the amount of data I have available to train on, as well as how widely spoken and studied a given language is. Here is a list of some of the top languages I can assist with: \\n\\n1. English (United States)\\n2. Mandarin (Chinese)\\n3. Spanish (Spain)\\n4. Hindi (India)\\n5. French (France)\\n6. Arabic (Saudi Arabia)\\n7. Portuguese (Brazil)\\n8. Japanese (Japan)\\n9. Russian (Russia)\\n10. Italian (Italy)\\n\\nHowever, as an AI language model, I can understand many more languages to different degrees, and I aim to continuously learn and improve my understanding through new data and updates.'},\n",
       " {'user_name': 'User',\n",
       "  'text': 'what is the proportion of Thai language that you trained'},\n",
       " {'user_name': 'Chatbot',\n",
       "  'text': \"My training data is comprised of many different languages, including Thai. I cannot provide specific details about the proportion or amount of language data I have been trained on, but can assure you that it encompasses a diverse range of languages from different populations and regions. \\n\\nYou can ask me specific questions in Thai, and I'll do my best to respond accurately and help you with the content you need.\"},\n",
       " {'user_name': 'User', 'text': 'ผีตาโขนอยู่จังหวัดอะไร'},\n",
       " {'user_name': 'Chatbot',\n",
       "  'text': 'I am unable to understand this query sentences as it is written in Thai. Please restate your question in English, or opt for a virtual keyboard if you would like to type in Thai.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mission abort, due to Laptop performance!\n",
    "## use API instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai_api)\n",
    "\n",
    "def get_response(messages, model=\"gpt-3.5-turbo-0125\", temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    #     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ถ้าคุณถูกรถชนและต้องการฟ้องคู่กรณี คุณสามารถทำตามขั้นตอนดังนี้:\n",
      "\n",
      "1. ระบุข้อมูลเกี่ยวกับเหตุการณ์: ระบุวันที่, เวลา, สถานที่ เหตุการณ์ที่เกิดขึ้น รวมถึงรายละเอียดเกี่ยวกับความเสียหายที่เกิดขึ้น เช่น ความเสียหายของรถ บุคคลที่ได้รับบาดเจ็บ ฯลฯ\n",
      "\n",
      "2. รวบรวมหลักฐาน: รวบรวมเอกสารหรือหลักฐานที่เกี่ยวข้อง เช่น รายงานการเกิดอุบัติเหตุ, รายละเอียดของพยาน, ฯลฯ\n",
      "\n",
      "3. ติดต่อกับบริษัทประกัน: ถ้ามีประกันภัย เริ่มต้นติดต่อกับบริษัทประกันของคู่กรณี เพื่อแจ้งเหตุการณ์และเริ่มกระบวนการเรียกร้องความเสียหาย\n",
      "\n",
      "4. รับคำปรึกษาจากทนาย: หากความเสียหายใหญ่หรือการเรียกร้องความเสียหายมีความซับซ้อน คุณสามารถค้นหาทนายที่เชี่ยวชาญด้านกฎหมายทางการบดี พูดคุยและรับคำปรึกษาเพื่อสนับสนุนกระบวนการทางกฎหมายของคุณ.\n",
      "\n",
      "ควรจำไว้ว่าขั้นตอนที่แจ้งไปข้างต้นเป็นเพียงแนวทางเท่านั้น และควรปฏิบัติตามกฎหมายและข้อบังคับท้องถิ่น.\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are law consultant chatbot.'},\n",
    "{'role':'user', 'content':'สวัสดี'},\n",
    "{'role':'assistant', 'content': \"สวัสดี ฉันชื่อ Saturday มีอะไรให้ฉันช่วยไหม?\"},\n",
    "{'role':'user', 'content':'ช่วยบอกทีว่าถูกรถชน จะฟ้องคู่กรณีได้ยังไง'}  ]\n",
    "\n",
    "response = get_response(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
